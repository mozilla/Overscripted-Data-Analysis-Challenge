{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/overscripted/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import tldextract\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sub samples and new samples with new columns/data will be saved under the \"DIR\" directory to keep things organized. \n",
    "As such, the function \"save_parquet\" and \"read_parquet\" adds this directory to every parquet name, and I'm using this functions instead of dd.read_parquet/dd.to_parquet direct to ensure the same read and write settings across the notebook. \n",
    "\n",
    "NOTE: each section adds its name to the 'FILE_NAME' and saves the new parquet with this name. Because of it, you can run the sections at any order you desire to have the output you need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing client / distributed\n",
    "# client = Client()\n",
    "# client\n",
    "\n",
    "#Create folder to save/read new data\n",
    "DIR = 'sample_0_prep/'\n",
    "FILE_NAME = 's0'\n",
    "\n",
    "if not os.path.exists(DIR):\n",
    "    os.makedirs(DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If no \"recalculate_partition\" is passed on, it will not recalculate the partitions. It is not mandatory, but good if you are significantly reducing the size of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save a DF to a parquet\n",
    "def save_parquet(df, name, recalculate_partition=False):\n",
    "    with ProgressBar():\n",
    "        #DF.REPARTITION copyed from: https://stackoverflow.com/questions/44657631/strategy-for-partitioning-dask-dataframes-efficiently\n",
    "        if recalculate_partition:\n",
    "            n = 1+df.memory_usage(deep=True).sum().compute() // (1000 * 1000 * 100)\n",
    "            print(\"Npartition: \", n)\n",
    "            df.repartition(npartitions= n).to_parquet(DIR + name + '.parquet', engine=\"pyarrow\")\n",
    "        else:\n",
    "            df.to_parquet(DIR + name + '.parquet', engine=\"pyarrow\")\n",
    "        \n",
    "        \n",
    "def read_parquet(name):\n",
    "    return dd.read_parquet(DIR + name + '.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Using 10% sample and self produced samples\n",
    " - 10% sample has 11292867 rows\n",
    " - Filtered by value_len > df.mean() has 499805 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['argument_0', 'argument_1', 'argument_2', 'argument_3', 'argument_4',\n",
       "       'argument_5', 'argument_6', 'argument_7', 'argument_8', 'arguments',\n",
       "       'arguments_n_keys', 'call_stack', 'crawl_id', 'file_name', 'func_name',\n",
       "       'in_iframe', 'location', 'operation', 'script_col', 'script_line',\n",
       "       'script_loc_eval', 'script_url', 'symbol', 'time_stamp', 'value',\n",
       "       'value_1000', 'value_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Original sample sample_0.parquet'\n",
    "df = dd.read_parquet('sample_0.parquet', \n",
    "                     engine='pyarrow', )\n",
    "#                      columns=['value_1000', 'value', 'value_len', 'symbol', 'script_url', 'location', 'operation'])\n",
    "\n",
    "# df.astype({'value_1000': str, 'value': str,'value_len': int,'symbol': int,'script_url': str})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DF overview\n",
    "Some overview about the sample: \n",
    "- Mean: 1356.97,\n",
    "- Min: 0,\n",
    "- Max: 4496861\n",
    "- Std: 26310.62"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 19.3s\n",
      "MEAN: 1356.9776628910975,\n",
      "MIN: 0,\n",
      "MAX: 4496861,\n",
      "std: 26310.62140481331,\n",
      "LEN: 11292867\n"
     ]
    }
   ],
   "source": [
    "with ProgressBar():\n",
    "    df_mean = df['value_len'].mean()\n",
    "    df_min = df['value_len'].min()\n",
    "    df_max = df['value_len'].max()\n",
    "    df_std = df['value_len'].std()\n",
    "    df_len = df['value_len'].count()\n",
    "    (df_mean, df_min, df_max, df_std, df_len) = dd.compute(df_mean, df_min, df_max, df_std, df_len);\n",
    "    print(\"MEAN: {},\\nMIN: {},\\nMAX: {},\\nstd: {},\\nLEN: {}\".format(df_mean, df_min, df_max, df_std, df_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column: Domains\n",
    "The following code is copyed from this same project: ~/analyses/hello_world.ipynb\n",
    "\n",
    "It uses the data saved from the last section\n",
    "This section is dedicated to extract the domain of the columns \"location\" and \"script_url\" and add it as new columns \"location_domain\" and \"script_domain\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME += '_domains'\n",
    "print('Notebook name: ', FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(url):\n",
    "    \"\"\"Use tldextract to return the base domain from a url\"\"\"\n",
    "    try:\n",
    "        extracted = tldextract.extract(url)\n",
    "        return '{}.{}'.format(extracted.domain, extracted.suffix)\n",
    "    except Exception as e:\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.astype({'value_1000': str, 'value': str,'value_len': int,'symbol': int,'script_url': str, 'location': str})\n",
    "df['location_domain'] = df.location.apply(extract_domain, meta='O')\n",
    "df['script_domain'] = df.script_url.apply(extract_domain, meta='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  7min 22.3s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name=FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location_domain</th>\n",
       "      <th>location</th>\n",
       "      <th>script_domain</th>\n",
       "      <th>script_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/widget_comments.php?app=2297596...</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/js/api/xdm.js?1449919642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/widget_comments.php?app=2297596...</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/js/api/xdm.js?1449919642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/widget_comments.php?app=2297596...</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>https://vk.com/js/al/aes_light.js?592436914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baidu.com</td>\n",
       "      <td>https://pos.baidu.com/s?hei=70&amp;wid=670&amp;di=u313...</td>\n",
       "      <td>baidustatic.com</td>\n",
       "      <td>https://cpro.baidustatic.com/cpro/ui/noexpire/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>serienjunkies.org</td>\n",
       "      <td>http://serienjunkies.org/smilf/smilf-season-1-...</td>\n",
       "      <td>google.com</td>\n",
       "      <td>https://apis.google.com/js/plusone.js?_=151338...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     location_domain                                           location  \\\n",
       "0             vk.com  https://vk.com/widget_comments.php?app=2297596...   \n",
       "1             vk.com  https://vk.com/widget_comments.php?app=2297596...   \n",
       "2             vk.com  https://vk.com/widget_comments.php?app=2297596...   \n",
       "3          baidu.com  https://pos.baidu.com/s?hei=70&wid=670&di=u313...   \n",
       "4  serienjunkies.org  http://serienjunkies.org/smilf/smilf-season-1-...   \n",
       "\n",
       "     script_domain                                         script_url  \n",
       "0           vk.com            https://vk.com/js/api/xdm.js?1449919642  \n",
       "1           vk.com            https://vk.com/js/api/xdm.js?1449919642  \n",
       "2           vk.com        https://vk.com/js/al/aes_light.js?592436914  \n",
       "3  baidustatic.com  https://cpro.baidustatic.com/cpro/ui/noexpire/...  \n",
       "4       google.com  https://apis.google.com/js/plusone.js?_=151338...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet(FILE_NAME)\n",
    "df[['location_domain',  'location', 'script_domain', 'script_url']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column:  is_json\n",
    "\n",
    "After manual initial analysis I have think that the huge values are json structured, to validate that I included an new column that is a boolean value with the validation of json\n",
    "\n",
    "After simple validation of value is a json or not, boolean value will be saved on a new column named \"is_json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME += '_isJson'\n",
    "print('Notebook name: ', FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_json(myjson):\n",
    "    if (myjson == '{}'):\n",
    "        #would be counted as valid, but its an empty json\n",
    "        return False\n",
    "    try:\n",
    "        #Eliminate false positives\n",
    "        return (type(json.loads(myjson)) == dict)\n",
    "    except ValueError as e:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_json'] = df['value'].apply(is_json, meta='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  5min 12.2s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name=FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>is_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  is_json\n",
       "0                                           fXDcab74    False\n",
       "1                                           fXDcab74    False\n",
       "2  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...    False\n",
       "3  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...    False\n",
       "4  _ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...    False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet(FILE_NAME)\n",
    "df[['value_1000', 'is_json']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add json keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the top level keys, sort them and add as a list into another column named 'json_keys'\n",
    "Will be using \"https://github.com/rnd0101/json_schema_inferencer\" to guess the json schema and save it into another column called \"json_schema\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME += '_jsonKeys'\n",
    "print('Notebook name: ', FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " def jsonKeys(r):\n",
    "    if(r['is_json']):\n",
    "        try:\n",
    "            dct = json.loads(r['value'])\n",
    "            keys = list(dct.keys())\n",
    "            keys.sort()\n",
    "            return str(keys)\n",
    "        except ValueError as e:\n",
    "            return ''\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  8min 32.7s\n"
     ]
    }
   ],
   "source": [
    "df['json_keys'] = df.apply(jsonKeys,axis=1, meta='O')\n",
    "save_parquet(df=df, name=FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>is_json</th>\n",
       "      <th>json_keys</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  is_json json_keys\n",
       "0                                           fXDcab74    False          \n",
       "1                                           fXDcab74    False          \n",
       "2  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...    False          \n",
       "3  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...    False          \n",
       "4  _ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...    False          "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read \n",
    "df = read_parquet(FILE_NAME)\n",
    "df[['value_1000', 'is_json', 'json_keys']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Column:  keys_md5\n",
    "Include new columns called \"keys_md5\" that is the md5 of json_keys column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys_md5\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME += '_md5'\n",
    "print('Notebook name: ', FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(value):\n",
    "    if (value == ''):\n",
    "        return ''\n",
    "    else:\n",
    "        return hashlib.md5(value.encode('utf-8')).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keys_md5'] = df['json_keys'].apply(md5, meta='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3min 49.6s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name=FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>keys_md5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fXDcab74</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000 keys_md5\n",
       "0                                           fXDcab74         \n",
       "1                                           fXDcab74         \n",
       "2  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...         \n",
       "3  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...         \n",
       "4  _ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...         "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet(FILE_NAME)\n",
    "df[['value_1000', 'keys_md5']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TLD\n",
    "Include new columns called \"script_tld\" that is the the TLD for the script_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys_md5_TLD\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME += '_TLD'\n",
    "print('Notebook name: ', FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractTLD(domain):\n",
    "    return domain.split('.')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['script_tld'] = df['script_domain'].apply(extractTLD, meta='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  3min 59.4s\n"
     ]
    }
   ],
   "source": [
    "#save\n",
    "save_parquet(df=df, name=FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>script_domain</th>\n",
       "      <th>script_tld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vk.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>baidustatic.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>google.com</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     script_domain script_tld\n",
       "0           vk.com        com\n",
       "1           vk.com        com\n",
       "2           vk.com        com\n",
       "3  baidustatic.com        com\n",
       "4       google.com        com"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read\n",
    "df = read_parquet(FILE_NAME)\n",
    "df[['script_domain', 'script_tld']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving other possible usefull filtered samples to future analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## value_len > df_mean\n",
    "1356 is the value_len mean\n",
    "\n",
    "To filter the data into something that is more interesting to this task I decided to only work with values that are at above the mean.\n",
    "\n",
    "All values above the mean count up to 499805 rows. That is just 4,42% of the whole sample, and a lot easier to work on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys_md5_TLD_above_mean\n"
     ]
    }
   ],
   "source": [
    "name = FILE_NAME + '_above_mean'\n",
    "print('Notebook name: ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  2min 23.6s\n"
     ]
    }
   ],
   "source": [
    "#Save\n",
    "save_parquet(df= df[df['value_len'] > df_mean], name= name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['argument_0', 'argument_1', 'argument_2', 'argument_3', 'argument_4',\n",
       "       'argument_5', 'argument_6', 'argument_7', 'argument_8', 'arguments',\n",
       "       'arguments_n_keys', 'call_stack', 'crawl_id', 'file_name', 'func_name',\n",
       "       'in_iframe', 'location', 'operation', 'script_col', 'script_line',\n",
       "       'script_loc_eval', 'script_url', 'symbol', 'time_stamp', 'value',\n",
       "       'value_1000', 'value_len', 'location_domain', 'script_domain',\n",
       "       'is_json', 'json_keys', 'keys_md5', 'script_tld'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read\n",
    "df = read_parquet(name)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter to parquet containing only JSON "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys_md5_TLD_JSON_ONLY\n"
     ]
    }
   ],
   "source": [
    "name = FILE_NAME + '_JSON_ONLY'\n",
    "print('Notebook name: ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  1min 20.0s\n"
     ]
    }
   ],
   "source": [
    "save_parquet(df=df[df['is_json'] == True], name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_1000</th>\n",
       "      <th>is_json</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          value_1000  is_json\n",
       "0  {\"im-settings\":\"{\\\"val\\\":{\\\"settings\\\":{\\\"Site...     True\n",
       "1  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "2  {\"APLUS_S_CORE_0.17.12_20171214163401_2ee09a0c...     True\n",
       "3  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...     True\n",
       "4  {\"dueljs_channel_comm\":\"[{\\\"id\\\":4734405521279...     True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read all_json_above_mean\n",
    "df = read_parquet(name)\n",
    "df[['value_1000', 'is_json']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All NON json above the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook name:  s0_domains_isJson_jsonKeys_md5_TLD_nonJSON_ONLY\n"
     ]
    }
   ],
   "source": [
    "name = FILE_NAME + '_nonJSON_ONLY'\n",
    "df = read_parquet(FILE_NAME)\n",
    "print('Notebook name: ', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed |  4min 34.1s\n",
      "Npartition:  285\n",
      "[########################################] | 100% Completed |  2min 11.3s\n"
     ]
    }
   ],
   "source": [
    "save_parquet(df=df[df['is_json'] == False], name=name, recalculate_partition=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>argument_0</th>\n",
       "      <th>argument_1</th>\n",
       "      <th>argument_2</th>\n",
       "      <th>argument_3</th>\n",
       "      <th>argument_4</th>\n",
       "      <th>argument_5</th>\n",
       "      <th>argument_6</th>\n",
       "      <th>argument_7</th>\n",
       "      <th>argument_8</th>\n",
       "      <th>arguments</th>\n",
       "      <th>...</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>value</th>\n",
       "      <th>value_1000</th>\n",
       "      <th>value_len</th>\n",
       "      <th>location_domain</th>\n",
       "      <th>script_domain</th>\n",
       "      <th>is_json</th>\n",
       "      <th>json_keys</th>\n",
       "      <th>keys_md5</th>\n",
       "      <th>script_tld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-16 19:02:31.406</td>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>8</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-16 19:02:31.407</td>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>fXDcab74</td>\n",
       "      <td>8</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-16 19:02:31.659</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>68</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-16 00:24:09.355</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...</td>\n",
       "      <td>68</td>\n",
       "      <td>baidu.com</td>\n",
       "      <td>baidustatic.com</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{}</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-12-16 01:24:30.372</td>\n",
       "      <td>_ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...</td>\n",
       "      <td>_ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...</td>\n",
       "      <td>288</td>\n",
       "      <td>serienjunkies.org</td>\n",
       "      <td>google.com</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  argument_0 argument_1 argument_2 argument_3 argument_4 argument_5  \\\n",
       "0       None       None       None       None       None       None   \n",
       "1       None       None       None       None       None       None   \n",
       "2       None       None       None       None       None       None   \n",
       "3       None       None       None       None       None       None   \n",
       "4       None       None       None       None       None       None   \n",
       "\n",
       "  argument_6 argument_7 argument_8 arguments  ...              time_stamp  \\\n",
       "0       None       None       None        {}  ... 2017-12-16 19:02:31.406   \n",
       "1       None       None       None        {}  ... 2017-12-16 19:02:31.407   \n",
       "2       None       None       None        {}  ... 2017-12-16 19:02:31.659   \n",
       "3       None       None       None        {}  ... 2017-12-16 00:24:09.355   \n",
       "4       None       None       None        {}  ... 2017-12-16 01:24:30.372   \n",
       "\n",
       "                                               value  \\\n",
       "0                                           fXDcab74   \n",
       "1                                           fXDcab74   \n",
       "2  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...   \n",
       "3  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...   \n",
       "4  _ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...   \n",
       "\n",
       "                                          value_1000 value_len  \\\n",
       "0                                           fXDcab74         8   \n",
       "1                                           fXDcab74         8   \n",
       "2  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...        68   \n",
       "3  Mozilla/5.0 (X11; Linux x86_64; rv:52.0) Gecko...        68   \n",
       "4  _ga=GA1.2.1529583939.1513387469; _gid=GA1.2.17...       288   \n",
       "\n",
       "     location_domain    script_domain is_json json_keys  keys_md5  script_tld  \n",
       "0             vk.com           vk.com   False                             com  \n",
       "1             vk.com           vk.com   False                             com  \n",
       "2             vk.com           vk.com   False                             com  \n",
       "3          baidu.com  baidustatic.com   False                             com  \n",
       "4  serienjunkies.org       google.com   False                             com  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read \n",
    "df = read_parquet(name)\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
